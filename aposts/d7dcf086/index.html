<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.shikun.work","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":true,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="环境 服务器信息，是腾讯云服务器，2核cpu，4GB内存，80GB云硬盘，系统为centos 7.6_x64  介绍Hadoop是用来处理大数据集合的分布式存储计算基础架构。可以使用一种简单的编程模式，通过多台计算机构成的集群，分布式处理大数据集。hadoop作为底层，其生态环境很丰富。hadoop基础包括以下四个基本模块：  hadoop基础功能库：支持其他hadoop模块的通用程序包。 HDF">
<meta property="og:type" content="article">
<meta property="og:title" content="第三章 大数据之Hadoop搭建">
<meta property="og:url" content="http://www.shikun.work/aposts/d7dcf086/index.html">
<meta property="og:site_name" content="施坤的博客">
<meta property="og:description" content="环境 服务器信息，是腾讯云服务器，2核cpu，4GB内存，80GB云硬盘，系统为centos 7.6_x64  介绍Hadoop是用来处理大数据集合的分布式存储计算基础架构。可以使用一种简单的编程模式，通过多台计算机构成的集群，分布式处理大数据集。hadoop作为底层，其生态环境很丰富。hadoop基础包括以下四个基本模块：  hadoop基础功能库：支持其他hadoop模块的通用程序包。 HDF">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.shikun.work/aposts/d7dcf086/image-20211207093705705.png">
<meta property="article:published_time" content="2021-12-07T01:18:51.000Z">
<meta property="article:modified_time" content="2022-02-25T03:20:56.699Z">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.shikun.work/aposts/d7dcf086/image-20211207093705705.png">

<link rel="canonical" href="http://www.shikun.work/aposts/d7dcf086/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>第三章 大数据之Hadoop搭建 | 施坤的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">施坤的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-简历">

    <a href="/resume/" rel="section"><i class="fa fa-address-card fa-fw"></i>简历</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.shikun.work/aposts/d7dcf086/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="一个正经的测试工程师">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="施坤的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第三章 大数据之Hadoop搭建
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-07 09:18:51" itemprop="dateCreated datePublished" datetime="2021-12-07T09:18:51+08:00">2021-12-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-02-25 11:20:56" itemprop="dateModified" datetime="2022-02-25T11:20:56+08:00">2022-02-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
            </span>

          
            <span id="/aposts/d7dcf086/" class="post-meta-item leancloud_visitors" data-flag-title="第三章 大数据之Hadoop搭建" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/aposts/d7dcf086/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/aposts/d7dcf086/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>服务器信息，是腾讯云服务器，2核cpu，4GB内存，80GB云硬盘，系统为centos 7.6_x64</li>
</ul>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Hadoop是用来处理大数据集合的分布式存储计算基础架构。可以使用一种简单的编程模式，通过多台计算机构成的集群，分布式处理大数据集。hadoop作为底层，其生态环境很丰富。hadoop基础包括以下四个基本模块：</p>
<ul>
<li>hadoop基础功能库：支持其他hadoop模块的通用程序包。</li>
<li>HDFS: 一个分布式文件系统，能够以高吞吐量访问应用的数据。</li>
<li>YARN: 一个作业调度和资源管理框架。</li>
<li>MapReduce: 一个基于YARN的大数据并行处理程序。</li>
</ul>
<h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h3 id="创建hadoop用户"><a href="#创建hadoop用户" class="headerlink" title="创建hadoop用户"></a>创建hadoop用户</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">su              <span class="comment">#  root 用户登录</span></span><br><span class="line">useradd -m hadoop -s /bin/bash   <span class="comment"># 创建新用户hadoop,并使用 /bin/bash 作为shell</span></span><br><span class="line">passwd hadoop <span class="comment"># 设置密码</span></span><br></pre></td></tr></table></figure>

<h4 id="设置权限"><a href="#设置权限" class="headerlink" title="设置权限"></a>设置权限</h4><ul>
<li><p>为 hadoop 用户增加管理员权限，方便部署，避免一些对新手来说比较棘手的权限问题，输入命令<code>visudo</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ sudo visudo</span><br><span class="line">[sudo] password for hadoop:</span><br></pre></td></tr></table></figure>


</li>
<li><p>找到 <code>root ALL=(ALL) ALL</code> 这行，然后在这行下面增加一行内容：<code>hadoop ALL=(ALL) ALL</code> （当中的间隔为tab），如下图所示：</p>
<p><img src="/aposts/d7dcf086/image-20211207093705705.png" alt="image-20211207093705705"></p>
</li>
<li><p><code>su hadoop</code> 直接可以切换用户</p>
</li>
</ul>
<h3 id="安装SSH、配置SSH无密码登陆"><a href="#安装SSH、配置SSH无密码登陆" class="headerlink" title="安装SSH、配置SSH无密码登陆"></a>安装SSH、配置SSH无密码登陆</h3><ul>
<li><p>集群、单节点模式都需要用到 SSH 登陆（类似于远程登陆，你可以登录某台 Linux 主机，并且在上面运行命令），一般情况下，CentOS 默认已安装了 SSH client、SSH server，打开终端执行如下命令进行检验：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos /]$ rpm -qa | grep ssh</span><br><span class="line">openssh-7.4p1-21.el7.x86_64</span><br><span class="line">openssh-clients-7.4p1-21.el7.x86_64</span><br><span class="line">openssh-server-7.4p1-21.el7.x86_64</span><br><span class="line">libssh2-1.8.0-4.el7.x86_64</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>包含了 SSH client 跟 SSH server，则不需要再安装</li>
</ul>
</li>
<li><p>接着执行如下命令(<code>ssh localhost</code>)测试一下 SSH 是否可用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos /]$ ssh localhost</span><br><span class="line">The authenticity of host <span class="string">&#x27;localhost (::1)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:v9LOJv5al8BNRGGZVJeqa2AdV3znIsa6cjyoj9CbWRQ.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is MD5:bd:51:9d:6f:1f:9c:1f:ad:34:ce:fb:90:4f:27:bc:b1.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>此时会有如下提示(SSH首次登陆提示)，输入 yes 。然后按提示输入密码 hadoop，这样就登陆到本机了，类似于下面这样：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Warning: Permanently added <span class="string">&#x27;localhost&#x27;</span> (ECDSA) to the list of known hosts.</span><br><span class="line">hadoop@localhost<span class="string">&#x27;s password:</span></span><br><span class="line"><span class="string">Last login: Tue Dec  7 09:37:37 2021</span></span><br><span class="line"><span class="string">[hadoop@VM-24-13-centos ~]$</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>但这样登陆是需要每次输入密码的，我们需要配置成SSH无密码登陆比较方便。</p>
</li>
<li><p>首先输入 <code>exit</code> 退出刚才的 ssh，就回到了我们原先的终端窗口，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos ~]$ <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line">Connection to localhost closed.</span><br><span class="line">[hadoop@VM-24-13-centos /]$</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/.ssh/                     <span class="comment"># 若没有该目录，请先执行一次ssh localhost</span></span><br><span class="line">ssh-keygen -t rsa              <span class="comment"># 会有提示，都按回车就可以</span></span><br><span class="line"><span class="built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys  <span class="comment"># 加入授权</span></span><br><span class="line"><span class="built_in">chmod</span> 600 ./authorized_keys    <span class="comment"># 修改文件权限</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>~的含义</strong></p>
<p>在 Linux 系统中，~ 代表的是用户的主文件夹，即 “&#x2F;home&#x2F;用户名” 这个目录，如你的用户名为 hadoop，则 ~ 就代表 “&#x2F;home&#x2F;hadoop&#x2F;”。 此外，命令中的 # 后面的文字是注释。</p>
</blockquote>
</li>
<li><p>此时再用 <code>ssh localhost</code> 命令，无需输入密码就可以直接登陆了，如下所示。</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@VM-24-13-centos .ssh]$ ssh localhost</span><br><span class="line">Last login: Tue Dec  7 09:44:00 2021 from ::1</span><br><span class="line">[hadoop@VM-24-13-centos ~]$</span><br></pre></td></tr></table></figure>

<h3 id="java"><a href="#java" class="headerlink" title="java"></a>java</h3><ul>
<li><p>java之前已经装好了，为1.8</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos ~]$ java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_311&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_311-b11)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.311-b11, mixed mode)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h3><ul>
<li>安装hadoop版本为3.0</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">su root</span><br><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line">wget https://archive.apache.org/dist/hadoop/common/hadoop-3.0.3/hadoop-3.0.3.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos <span class="built_in">local</span>]$ sudo tar zxvf hadoop-3.0.3.tar.gz</span><br><span class="line"><span class="built_in">cd</span> /usr/local/</span><br><span class="line">sudo <span class="built_in">mv</span> ./hadoop-3.0.3/ ./hadoop            <span class="comment"># 将文件夹名改为hadoop</span></span><br><span class="line">sudo <span class="built_in">chown</span> -R hadoop:hadoop ./hadoop        <span class="comment"># 修改文件权限</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>Hadoop 解压后即可使用。输入如下命令来检查 Hadoop 是否可用，成功则会显示 Hadoop 版本信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/hadoop</span><br><span class="line">./bin/hadoop version</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hadoop version</span><br><span class="line">Hadoop 3.0.3</span><br><span class="line">Source code repository https://yjzhangal@git-wip-us.apache.org/repos/asf/hadoop.git -r 37fd7d752db73d984dc31e0cdfd590d252f5e075</span><br><span class="line">Compiled by yzhang on 2018-05-31T17:12Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 736cdcefa911261ad56d2d120bf1fa</span><br><span class="line">This <span class="built_in">command</span> was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.0.3.jar</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Hadoop单机配置-非分布式"><a href="#Hadoop单机配置-非分布式" class="headerlink" title="Hadoop单机配置(非分布式)"></a>Hadoop单机配置(非分布式)</h2><ul>
<li>Hadoop 默认模式为非分布式模式，无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。</li>
<li><strong>这里比较奇怪，安装原文中教程，示例已经验证通过了，当搭建了伪分布式配置时，第二天运行这里的实例，没有成功？然后把实例修改后，发现居然和伪分布式配置代码差不多？暂不做深究了</strong></li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><ul>
<li><p>现在我们可以执行例子来感受下 Hadoop 的运行。Hadoop 附带了丰富的例子（运行 <code>./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.3.jar</code> 可以看到所有例子），包括 wordcount、terasort、join、grep 等。</p>
</li>
<li><p>在此我们选择运行 wordcount例子，我们将 input 文件夹中的所有文件作为输入，最后输出结果到 output 文件夹中。</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/hadoop</span><br><span class="line">mkdri iniput1</span><br><span class="line"><span class="built_in">cp</span> ./etc/hadoop/*.xml ./input1</span><br><span class="line"><span class="comment"># 在HDFS创建一个目录</span></span><br><span class="line">hdfs dfs -<span class="built_in">mkdir</span> /usr/local/hadoop/input</span><br><span class="line"><span class="comment">#  将配置文件作为输入文件上传到刚创建的HDFS目录中</span></span><br><span class="line">hdfs dfs -put ./input1/* /usr/local/hadoop/input</span><br><span class="line"></span><br><span class="line">hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar wordcount /usr/local/hadoop/input /usr/local/hadoop/output </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行结果列表</span></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ hdfs dfs -<span class="built_in">ls</span> /usr/local/hadoop/output/*</span><br><span class="line"></span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2021-12-10 16:48 /usr/local/hadoop/output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       9405 2021-12-10 16:48 /usr/local/hadoop/output/part-r-00000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用cat查运行数据</span></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ hdfs dfs -<span class="built_in">cat</span> /usr/local/hadoop/output/part-r-00000</span><br><span class="line">...</span><br><span class="line">datanodes       1</span><br><span class="line">decryptEncryptedKey     1</span><br><span class="line">default 13</span><br><span class="line">default_priority=&#123;priority&#125;]    1</span><br><span class="line">defined.        4</span><br><span class="line">delete-key      1</span><br><span class="line">dfsadmin        1</span><br><span class="line">different   </span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>注意</strong>，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 <code>./output</code> 删除。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ hdfs dfs -<span class="built_in">rm</span> -r /usr/local/hadoop/output</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Hadoop伪分布式配置"><a href="#Hadoop伪分布式配置" class="headerlink" title="Hadoop伪分布式配置"></a>Hadoop伪分布式配置</h2><ul>
<li>Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，<strong>节点既作为 NameNode 也作为 DataNode，同时读取的是 HDFS 中的文件</strong>。</li>
</ul>
<h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><ul>
<li>在设置 Hadoop 伪分布式配置前，我们还需要设置 HADOOP 环境变量，执行如下命令在 ~&#x2F;.bashrc 中设置：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"># Hadoop Environment Variables</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop # hadoop的安装路径</span><br><span class="line">export HADOOP_INSTALL=$HADOOP_HOME</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME # 设置MAPRED环境变量</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME # 设置COMMON环境变量</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME # HDFS的环境变量</span><br><span class="line">export YARN_HOME=$HADOOP_HOME # YARN的环境变量</span><br><span class="line">export JAVA_HOME=/usr/local/jdk1.8.0_311 # 设置jdk的安装目录（用which java查看到）</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br></pre></td></tr></table></figure>

<ul>
<li><p>生效环境变量</p>
<p> <code>source ~/.bashrc</code></p>
</li>
<li><p>修改Hadoop-env.sh中的java_home，不然在启动集群（伪集群）时出现报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh</span><br><span class="line"></span><br><span class="line"># 设置如下</span><br><span class="line">export JAVA_HOME=/usr/local/jdk1.8.0_311</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><ul>
<li><p>Hadoop 的配置文件位于 <code>/usr/local/hadoop/etc/hadoop/</code> 中，伪分布式需要修改2个配置文件 <strong>core-site.xml</strong> 和 <strong>hdfs-site.xml</strong></p>
</li>
<li><p>Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>
</li>
<li><p>修改配置文件 <strong>core-site.xml</strong> </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /usr/local/hadoop/etc/hadoop/core-site.xml </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 设置HDFS的默认名称，在使用命令调用时，可以用此名称</span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>同样的，修改配置文件 <strong>hdfs-site.xml</strong>：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>设置blocks副本数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>设置存放NameNode的数据存储目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>设置存放DataNode的数据存储目录<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置完成后，执行 NameNode 的格式化:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>接着开启 <code>NaneNode</code> 和 <code>DataNode</code> 守护进程，<code>./sbin/start-dfs.sh</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./sbin/start-dfs.sh</span><br><span class="line">Starting namenodes on [localhost]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [VM-24-13-centos]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动完成后，可以通过命令 <code>jps</code> 来判断是否成功启动，若成功启动则会列出如下进程: <code>NameNode</code>、<code>DataNode</code>和<code>SecondaryNameNode</code>（如果 SecondaryNameNode 没有启动，请运行 sbin&#x2F;stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ jps</span><br><span class="line">12433 Jps</span><br><span class="line">11741 DataNode</span><br><span class="line">11597 NameNode</span><br><span class="line">11934 SecondaryNameNode</span><br><span class="line"><span class="comment"># HDFS功能：NameNode，SecondaryNameNode，DataNode已经启动</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>通过查看启动日志分析启动失败原因</strong></p>
<p>有时 Hadoop 无法正确启动，如 NameNode 进程没有顺利启动，这时可以查看启动日志来排查原因，注意几点：</p>
<ul>
<li>启动时会提示形如 “dblab: starting namenode, logging to &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;logs&#x2F;hadoop-hadoop-namenode-dblab.out”，其中 dblab 对应你的主机名，但启动的日志信息是记录在 &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;logs&#x2F;hadoop-hadoop-namenode-dblab.log 中，所以应该查看这个后缀为 <strong>.log</strong> 的文件；</li>
<li>每一次的启动日志都是追加在日志文件之后，所以得拉到最后面看，看下记录的时间就知道了。</li>
<li>一般出错的提示在最后面，也就是写着 Fatal、Error 或者 Java Exception 的地方。</li>
<li>可以在网上搜索一下出错信息，看能否找到一些相关的解决方法。</li>
</ul>
</blockquote>
<h3 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h3><ul>
<li><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hdfs dfs -<span class="built_in">mkdir</span> -p /user/hadoop</span><br><span class="line">2021-12-07 16:25:32,492 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br></pre></td></tr></table></figure>
</li>
<li><p>接着将·<code>./etc/hadoop</code>中的 xml 文件作为输入文件复制到分布式文件系统中，即将<code> /usr/local/hadoop/etc/hadoop</code> 复制到分布式文件系统中的<code>/user/hadoop/input</code>中。我们使用的是 hadoop 用户，并且已创建相应的用户目录<code> /user/hadoop</code> ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是<code> /user/hadoop/input</code></p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -<span class="built_in">mkdir</span> input</span><br><span class="line">./bin/hdfs dfs -put ./etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>

<ul>
<li><p>复制完成后，可以通过如下命令查看 HDFS 中的文件列表：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hdfs dfs -<span class="built_in">ls</span> input</span><br><span class="line"></span><br><span class="line">Found 9 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       7861 2021-12-07 16:28 input/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       1071 2021-12-07 16:28 input/core-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup      10206 2021-12-07 16:28 input/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       1339 2021-12-07 16:28 input/hdfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        620 2021-12-07 16:28 input/httpfs-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       3518 2021-12-07 16:28 input/kms-acls.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        682 2021-12-07 16:28 input/kms-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        758 2021-12-07 16:28 input/mapred-site.xml</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        690 2021-12-07 16:28 input/yarn-site.xml</span><br></pre></td></tr></table></figure>
</li>
<li><p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar  wordcount input output </span><br><span class="line">....</span><br><span class="line">2021-12-07 16:30:56,021 INFO mapreduce.Job: Job job_local897809468_0002 completed successfully</span><br><span class="line">...</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hdfs dfs -<span class="built_in">ls</span> output/*</span><br><span class="line"></span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2021-12-10 17:58 output/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup       9405 2021-12-10 17:58 output/part-r-00000</span><br><span class="line"></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ ./bin/hdfs dfs -<span class="built_in">cat</span> output/part-r-00000</span><br><span class="line">....</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>我们也可以将运行结果取回到本地：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -r ./output    <span class="comment"># 先删除本地的 output 文件夹（如果存在）</span></span><br><span class="line">./bin/hdfs dfs -get output ./output     <span class="comment"># 将 HDFS 上的 output 文件夹拷贝到本机</span></span><br><span class="line">[hadoop@VM-24-13-centos hadoop]$ <span class="built_in">cat</span> ./output/*</span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 <code>org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists</code>，因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -rm -r output    # 删除 output 文件夹</span><br></pre></td></tr></table></figure>

<ul>
<li>为防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，运行前需要先删除输出目录。在实际开发应用程序时，可考虑在程序中加上如下代码，能在每次运行时自动删除输出目录，避免繁琐的命令行操作，可以采用类似于下面java代码：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"><span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Job</span>(conf);</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 删除输出目录 */</span></span><br><span class="line"><span class="type">Path</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">outputPath.getFileSystem(conf).delete(outputPath, <span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li><p>若要关闭 Hadoop，则运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 <code>./sbin/start-dfs.sh</code> 就可以！</p>
</li>
</ul>
<h2 id="完全分布式"><a href="#完全分布式" class="headerlink" title="完全分布式"></a>完全分布式</h2><p>后续打算采用本地三台虚拟机的模式搭建完全分布式。</p>
<p>请注意分布式运行中的这几个结点的区别：</p>
<ul>
<li>从分布式存储的角度来说，集群中的结点由一个NameNode和若干个DataNode组成,另有一个SecondaryNameNode作为NameNode的备份。</li>
<li>从分布式应用的角度来说，集群中的结点由一个JobTracker和若干个TaskTracker组成，JobTracker负责任务的调度，TaskTracker负责并行执行任务。TaskTracker必须运行在DataNode上，这样便于数据的本地计算。JobTracker和NameNode则无须在同一台机器上。一个机器上，既当namenode，又当datanode,或者说 既 是jobtracker,又是tasktracker。没有所谓的在多台机器上进行真正的分布式计算，故称为”伪分布式”。</li>
<li>真正的分布式，由3个及以上的实体机或者虚拟机组件的机群。</li>
<li>来自<a target="_blank" rel="noopener" href="https://www.cnblogs.com/liango/p/7116620.html">这里</a></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><p><a target="_blank" rel="noopener" href="http://dblab.xmu.edu.cn/blog/install-hadoop-in-centos/">Hadoop安装教程_伪分布式配置_CentOS6.4&#x2F;Hadoop2.6.0</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/43cfffe7090d">ubuntn-Hadoop 单台Cluster的安装</a></p>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/aposts/8ae2490c/" rel="prev" title="第二章 数据仓的设计与构建">
      <i class="fa fa-chevron-left"></i> 第二章 数据仓的设计与构建
    </a></div>
      <div class="post-nav-item">
    <a href="/aposts/ae85ee2e/" rel="next" title="第四章 大数据之hive搭建">
      第四章 大数据之hive搭建 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">


    <div class="sidebar-inner">



      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83"><span class="nav-number">1.</span> <span class="nav-text">环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="nav-number">3.</span> <span class="nav-text">安装配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BAhadoop%E7%94%A8%E6%88%B7"><span class="nav-number">3.1.</span> <span class="nav-text">创建hadoop用户</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE%E6%9D%83%E9%99%90"><span class="nav-number">3.1.1.</span> <span class="nav-text">设置权限</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85SSH%E3%80%81%E9%85%8D%E7%BD%AESSH%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86"><span class="nav-number">3.2.</span> <span class="nav-text">安装SSH、配置SSH无密码登陆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#java"><span class="nav-number">3.3.</span> <span class="nav-text">java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85hadoop"><span class="nav-number">3.4.</span> <span class="nav-text">安装hadoop</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E5%8D%95%E6%9C%BA%E9%85%8D%E7%BD%AE-%E9%9D%9E%E5%88%86%E5%B8%83%E5%BC%8F"><span class="nav-number">4.</span> <span class="nav-text">Hadoop单机配置(非分布式)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B"><span class="nav-number">4.1.</span> <span class="nav-text">实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE"><span class="nav-number">5.</span> <span class="nav-text">Hadoop伪分布式配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">5.1.</span> <span class="nav-text">设置环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">5.2.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B-1"><span class="nav-number">5.3.</span> <span class="nav-text">实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F"><span class="nav-number">6.</span> <span class="nav-text">完全分布式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">7.</span> <span class="nav-text">参考</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt=""
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">一个正经的测试工程师</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">143</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">62</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Louis-me" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Louis-me" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shikun.job@foxmail.com" title="E-Mail → mailto:shikun.job@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
  <!-- 标签云 -->

<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <!--<h3 class="widget-title">Tag Cloud</h3> -->
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AWVS/" rel="tag">AWVS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/" rel="tag">Android</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Burp-Site/" rel="tag">Burp Site</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DVWA/" rel="tag">DVWA</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dependency-Check/" rel="tag">Dependency-Check</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/H5/" rel="tag">H5</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins/" rel="tag">Jenkins</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Metasploit/" rel="tag">Metasploit</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nessus/" rel="tag">Nessus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sonic/" rel="tag">Sonic</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/airtest/" rel="tag">airtest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/android/" rel="tag">android</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/android%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/" rel="tag">android性能测试</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/app%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/" rel="tag">app安全测试</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/aritest/" rel="tag">aritest</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/centos/" rel="tag">centos</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chrome/" rel="tag">chrome</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/datax/" rel="tag">datax</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/django/" rel="tag">django</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/drozer/" rel="tag">drozer</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fisco-bcos/" rel="tag">fisco-bcos</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/" rel="tag">flink</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gin/" rel="tag">gin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/" rel="tag">go</a><span class="tag-list-count">16</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go-zero/" rel="tag">go-zero</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/" rel="tag">hive</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/httprunner/" rel="tag">httprunner</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jmeter/" rel="tag">jmeter</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kail/" rel="tag">kail</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode-%E6%95%B0%E7%BB%84/" rel="tag">leetcode-数组</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mitmproxy/" rel="tag">mitmproxy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/monkey/" rel="tag">monkey</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pc%E8%87%AA%E5%8A%A8%E5%8C%96/" rel="tag">pc自动化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/playwright/" rel="tag">playwright</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytest/" rel="tag">pytest</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">23</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/" rel="tag">redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/selenium/" rel="tag">selenium</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlite/" rel="tag">sqlite</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqlmap/" rel="tag">sqlmap</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tkinter/" rel="tag">tkinter</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/" rel="tag">vue</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue3/" rel="tag">vue3</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/" rel="tag">云服务器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/" rel="tag">区块链</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/" rel="tag">安全测试</a><span class="tag-list-count">29</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/" rel="tag">性能测试</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" rel="tag">环境搭建</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/" rel="tag">自动化测试</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/" rel="tag">英语学习</a><span class="tag-list-count">1</span></li></ul>
        </canvas>
    </div>
</div>

</div>
<!-- 标签云 -->
    </div>

  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  <a href="https://beian.miit.gov.cn/" target="_blank">湘ICP备2022002212号-1</a><br />
  <!--
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
  -->
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>


        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  


<script src='../../../js/src/av-min.js'></script>
<script src='../../../js/src/Valine.min.js'></script>

<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : true,
      notify     : false,
      appId      : 'mhSm1aOQmnVeiAUJxrsKIFg5-gzGzoHsz',
      appKey     : 'kW6GQVoeJac7wDgKvy9vXhn6',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
